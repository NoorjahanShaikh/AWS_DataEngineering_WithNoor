# AWS_DataEngineering_WithNoor
# ğŸŒŸ CDC - Change Data Capture Project ğŸš€

CDC - Change Data Capture ! Here, we embark on an exciting journey through the landscape of AWS data engineering, transforming and transporting data in innovative ways.

## ğŸ› ï¸ Building Blocks of project

### 1ï¸âƒ£ ğŸ›¡ï¸ IAM Roles & Security Groups: Our Guardians
Setting up IAM Roles and Security Groups is like crafting shields and armor for our data, ensuring safety and proper access.

### 2ï¸âƒ£ ğŸŒ RDS (MySQL) - The Origin of Our Quest
Our adventure starts at the rich data lands of RDS MySQL, where our initial treasure trove of data lies.

## ğŸš¢ The DMS Voyage

### 2.1 ğŸ“¡ Source Endpoint: The Scout
Employing DMS as our scout to navigate and gather data from the MySQL.

### 2.2 ğŸŒŒ Destination Endpoint: 
Charting a course to store our data in the cosmic vault of Amazon S3.

### 2.3 ğŸ›¤ï¸ DMS Task:
This task is our pathway, ensuring a steady and smooth journey of data from source to destination connection.

## ğŸŒ  Amazon S3 

Our data finds its home in Amazon S3, the storage of the cloud, known for its security and vastness.

## ğŸª„ AWS Lambda - The Magic Touch

### 4.1 ğŸ”® Trigger: The Magic Spell
Casting a Lambda spell to automatically awaken and process new data arrivals in S3.

## ğŸŒˆ AWS Glue - The Alchemy of Data

### 5.1 ğŸŒ€ Change Data Capture (CDC): The Transformation
Embracing the magic of AWS Glue for our Change Data Capture - a process where data undergoes a magnificent transformation.

### 5.2 ğŸŒŸ CloudWatch: The Monitoring tool 
Utilizing CloudWatch, our seer, to gaze into the depths of our data processes and transformations.

### 5.3 ğŸ”™ Return to S3: The Cycle Continues
After its transformation, data is sent back to its resting place in S3, ready for its next adventure.

### 5.4 ğŸ“œ PySpark & Boto3: The Wizards' Tools
Wielding the tools of PySpark and the Boto3 library, we craft spells (scripts) to automate and control our AWS journey.

## ğŸ“š Databricks - The Enchanters' Workshop

In the mystical workshop of Databricks, we write, test, and refine our enchantments (code) for the journey ahead.

You can follow this flow to implement:

1. Clone the repository to begin your journey.
2. Forge your IAM roles and security groups as your protective gear.
3. Prepare the RDS MySQL for its role in this grand tale.
4. Set up the DMS service as your guide across the data realms.
5. Use Lambda magic to respond to new arrivals in S3.
6. Master the art of AWS Glue for Change Data Capture.
7. Seek wisdom from CloudWatch, the all-seeing oracle.
8. Craft and test your magical scripts in PySpark and Boto3, with Databricks as your arcane laboratory.

Dive into the code, contribute your discoveries, and seek assistance on this learning!

Happy coding ğŸ‰
